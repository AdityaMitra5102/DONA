{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sending my training plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_update_id = None\n",
    "\n",
    "def send_telegram_message(message):\n",
    "    TOKEN = '7166875544:AAGBi7azOdXowUbrZKXHpm7p152pG-mDxkA'  #creds\n",
    "    chat_id = '5255840420'  #creds\n",
    "    url = f\"https://api.telegram.org/bot{TOKEN}/sendMessage?chat_id={chat_id}&text={message}\"\n",
    "    response = requests.get(url)\n",
    "    print(f\"Sent message: {message}, Response: {response.json()}\")\n",
    "\n",
    "def send_telegram_image(image_path):\n",
    "    TOKEN = '7166875544:AAGBi7azOdXowUbrZKXHpm7p152pG-mDxkA'  #creds\n",
    "    chat_id = '5255840420'  #creds\n",
    "    url = f\"https://api.telegram.org/bot{TOKEN}/sendPhoto\"\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        files = {'photo': image_file}\n",
    "        data = {'chat_id': chat_id}\n",
    "        response = requests.post(url, files=files, data=data)\n",
    "    print(f\"Sent image: {image_path}, Response: {response.json()}\")\n",
    "\n",
    "def get_updates(offset=None):\n",
    "    TOKEN = '7166875544:AAGBi7azOdXowUbrZKXHpm7p152pG-mDxkA'  #creds\n",
    "    url = f\"https://api.telegram.org/bot{TOKEN}/getUpdates\"\n",
    "    params = {'offset': offset, 'timeout': 30}\n",
    "    response = requests.get(url, params=params).json()\n",
    "    return response.get('result', [])\n",
    "\n",
    "def clear_previous_messages():\n",
    "    global last_update_id\n",
    "    updates = get_updates()\n",
    "    if updates:\n",
    "        last_update_id = updates[-1]['update_id'] + 1\n",
    "    print(f\"Cleared previous messages. Last update ID: {last_update_id}\")\n",
    "\n",
    "def request_next_command():\n",
    "    global last_update_id\n",
    "    send_telegram_message(\"Please enter the next command (rerun, stop):\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    timeout = 300  # 5 minutes timeout\n",
    "\n",
    "    while time.time() - start_time < timeout:\n",
    "        updates = get_updates(last_update_id)\n",
    "        for update in updates:\n",
    "            last_update_id = update['update_id'] + 1\n",
    "            if 'message' in update and 'text' in update['message']:\n",
    "                command = update['message']['text'].lower()\n",
    "                if command in ['rerun', 'stop']:return command\n",
    "                else:send_telegram_message(\"Invalid command. Please enter 'rerun' to rerun or 'stop' to stop training.\")\n",
    "        time.sleep(1)\n",
    "    send_telegram_message(\"No valid command received within 5 minutes. Stopping the program.\")\n",
    "    return \"stop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(nn.Linear(28*28, 512),nn.ReLU(),nn.Linear(512, 10))\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        return self.linear_relu_stack(x)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "model = SimpleNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_model(num_epochs, train_loader, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        epoch_loss /= len(train_loader)\n",
    "        epoch_losses.append(epoch_loss)\n",
    "        print(f'Epoch {epoch+1}, Loss: {epoch_loss:.4f}')\n",
    "    return epoch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleared previous messages. Last update ID: 265526397\n",
      "Sent message: Model training has started., Response: {'ok': True, 'result': {'message_id': 218, 'from': {'id': 7166875544, 'is_bot': True, 'first_name': 'anorak', 'username': 'gladiator_anorak_bot'}, 'chat': {'id': 5255840420, 'first_name': 'Anorak', 'type': 'private'}, 'date': 1721909349, 'text': 'Model training has started.'}}\n",
      "Epoch 1, Loss: 0.3111\n",
      "Epoch 2, Loss: 0.1430\n",
      "Sent message: Training complete. Final loss: 0.1430, Response: {'ok': True, 'result': {'message_id': 219, 'from': {'id': 7166875544, 'is_bot': True, 'first_name': 'anorak', 'username': 'gladiator_anorak_bot'}, 'chat': {'id': 5255840420, 'first_name': 'Anorak', 'type': 'private'}, 'date': 1721909473, 'text': 'Training complete. Final loss: 0.1430'}}\n",
      "Sent image: training_loss_plot.png, Response: {'ok': True, 'result': {'message_id': 220, 'from': {'id': 7166875544, 'is_bot': True, 'first_name': 'anorak', 'username': 'gladiator_anorak_bot'}, 'chat': {'id': 5255840420, 'first_name': 'Anorak', 'type': 'private'}, 'date': 1721909474, 'photo': [{'file_id': 'AgACAgUAAxkDAAPcZqJA4uvTUkarFlmTvzlVJSqlW0UAAgnBMRtpGxFVHUm0LRj-Am8BAAMCAANzAAM1BA', 'file_unique_id': 'AQADCcExG2kbEVV4', 'file_size': 735, 'width': 90, 'height': 45}, {'file_id': 'AgACAgUAAxkDAAPcZqJA4uvTUkarFlmTvzlVJSqlW0UAAgnBMRtpGxFVHUm0LRj-Am8BAAMCAANtAAM1BA', 'file_unique_id': 'AQADCcExG2kbEVVy', 'file_size': 7465, 'width': 320, 'height': 160}, {'file_id': 'AgACAgUAAxkDAAPcZqJA4uvTUkarFlmTvzlVJSqlW0UAAgnBMRtpGxFVHUm0LRj-Am8BAAMCAAN4AAM1BA', 'file_unique_id': 'AQADCcExG2kbEVV9', 'file_size': 27780, 'width': 800, 'height': 400}, {'file_id': 'AgACAgUAAxkDAAPcZqJA4uvTUkarFlmTvzlVJSqlW0UAAgnBMRtpGxFVHUm0LRj-Am8BAAMCAAN5AAM1BA', 'file_unique_id': 'AQADCcExG2kbEVV-', 'file_size': 33619, 'width': 1000, 'height': 500}]}}\n",
      "Sent message: Please enter the next command (rerun, stop):, Response: {'ok': True, 'result': {'message_id': 221, 'from': {'id': 7166875544, 'is_bot': True, 'first_name': 'anorak', 'username': 'gladiator_anorak_bot'}, 'chat': {'id': 5255840420, 'first_name': 'Anorak', 'type': 'private'}, 'date': 1721909475, 'text': 'Please enter the next command (rerun, stop):'}}\n",
      "Sent message: Rerunning the training., Response: {'ok': True, 'result': {'message_id': 223, 'from': {'id': 7166875544, 'is_bot': True, 'first_name': 'anorak', 'username': 'gladiator_anorak_bot'}, 'chat': {'id': 5255840420, 'first_name': 'Anorak', 'type': 'private'}, 'date': 1721909480, 'text': 'Rerunning the training.'}}\n",
      "Sent message: Model training has started., Response: {'ok': True, 'result': {'message_id': 224, 'from': {'id': 7166875544, 'is_bot': True, 'first_name': 'anorak', 'username': 'gladiator_anorak_bot'}, 'chat': {'id': 5255840420, 'first_name': 'Anorak', 'type': 'private'}, 'date': 1721909480, 'text': 'Model training has started.'}}\n",
      "Epoch 1, Loss: 0.1044\n",
      "Epoch 2, Loss: 0.0860\n",
      "Sent message: Training complete. Final loss: 0.0860, Response: {'ok': True, 'result': {'message_id': 225, 'from': {'id': 7166875544, 'is_bot': True, 'first_name': 'anorak', 'username': 'gladiator_anorak_bot'}, 'chat': {'id': 5255840420, 'first_name': 'Anorak', 'type': 'private'}, 'date': 1721909609, 'text': 'Training complete. Final loss: 0.0860'}}\n",
      "Sent image: training_loss_plot.png, Response: {'ok': True, 'result': {'message_id': 226, 'from': {'id': 7166875544, 'is_bot': True, 'first_name': 'anorak', 'username': 'gladiator_anorak_bot'}, 'chat': {'id': 5255840420, 'first_name': 'Anorak', 'type': 'private'}, 'date': 1721909610, 'photo': [{'file_id': 'AgACAgUAAxkDAAPiZqJBanEjV5A7y-I5rpFk5GaGqhIAAgrBMRtpGxFVAsmK58YfoQsBAAMCAANzAAM1BA', 'file_unique_id': 'AQADCsExG2kbEVV4', 'file_size': 758, 'width': 90, 'height': 45}, {'file_id': 'AgACAgUAAxkDAAPiZqJBanEjV5A7y-I5rpFk5GaGqhIAAgrBMRtpGxFVAsmK58YfoQsBAAMCAANtAAM1BA', 'file_unique_id': 'AQADCsExG2kbEVVy', 'file_size': 8242, 'width': 320, 'height': 160}, {'file_id': 'AgACAgUAAxkDAAPiZqJBanEjV5A7y-I5rpFk5GaGqhIAAgrBMRtpGxFVAsmK58YfoQsBAAMCAAN4AAM1BA', 'file_unique_id': 'AQADCsExG2kbEVV9', 'file_size': 29648, 'width': 800, 'height': 400}, {'file_id': 'AgACAgUAAxkDAAPiZqJBanEjV5A7y-I5rpFk5GaGqhIAAgrBMRtpGxFVAsmK58YfoQsBAAMCAAN5AAM1BA', 'file_unique_id': 'AQADCsExG2kbEVV-', 'file_size': 37760, 'width': 1000, 'height': 500}]}}\n",
      "Sent message: Please enter the next command (rerun, stop):, Response: {'ok': True, 'result': {'message_id': 227, 'from': {'id': 7166875544, 'is_bot': True, 'first_name': 'anorak', 'username': 'gladiator_anorak_bot'}, 'chat': {'id': 5255840420, 'first_name': 'Anorak', 'type': 'private'}, 'date': 1721909611, 'text': 'Please enter the next command (rerun, stop):'}}\n",
      "Sent message: Training stopped by user command., Response: {'ok': True, 'result': {'message_id': 229, 'from': {'id': 7166875544, 'is_bot': True, 'first_name': 'anorak', 'username': 'gladiator_anorak_bot'}, 'chat': {'id': 5255840420, 'first_name': 'Anorak', 'type': 'private'}, 'date': 1721909613, 'text': 'Training stopped by user command.'}}\n"
     ]
    }
   ],
   "source": [
    "clear_previous_messages()\n",
    "\n",
    "while True:\n",
    "    send_telegram_message(\"Model training has started.\")\n",
    "    epoch_losses = train_model(2, train_loader, model, criterion, optimizer)\n",
    "    final_loss = epoch_losses[-1]\n",
    "    send_telegram_message(f\"Training complete. Final loss: {final_loss:.4f}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epoch_losses, marker='o', linestyle='-', color='b')\n",
    "    plt.title('Training Loss Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('training_loss_plot.png')\n",
    "    plt.close()\n",
    "\n",
    "    send_telegram_image('training_loss_plot.png')\n",
    "\n",
    "    command = request_next_command()\n",
    "    if command == \"stop\":\n",
    "        send_telegram_message(\"Training stopped by user command.\")\n",
    "        break\n",
    "    elif command == \"rerun\":\n",
    "        send_telegram_message(\"Rerunning the training.\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "last_update_id = None\n",
    "\n",
    "# ... (keep the existing send_telegram_message, send_telegram_image, get_updates, and clear_previous_messages functions)\n",
    "\n",
    "def request_user_input(prompt):\n",
    "    global last_update_id\n",
    "    send_telegram_message(prompt)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    timeout = 300  # 5 minutes timeout\n",
    "\n",
    "    while time.time() - start_time < timeout:\n",
    "        updates = get_updates(last_update_id)\n",
    "        for update in updates:\n",
    "            last_update_id = update['update_id'] + 1\n",
    "            if 'message' in update and 'text' in update['message']:\n",
    "                return update['message']['text'].lower()\n",
    "        time.sleep(1)\n",
    "    \n",
    "    send_telegram_message(\"No input received within 5 minutes. Using default value.\")\n",
    "    return None\n",
    "\n",
    "def get_hyperparameters():\n",
    "    choice = request_user_input(\"Do you want to input hyperparameters? (yes/no)\")\n",
    "    \n",
    "    if choice == 'yes':\n",
    "        learning_rate = float(request_user_input(\"Enter learning rate (e.g., 0.001):\") or 0.001)\n",
    "        batch_size = int(request_user_input(\"Enter batch size (e.g., 64):\") or 64)\n",
    "        num_epochs = int(request_user_input(\"Enter number of epochs (e.g., 2):\") or 2)\n",
    "        hidden_size = int(request_user_input(\"Enter hidden layer size (e.g., 512):\") or 512)\n",
    "    else:\n",
    "        learning_rate = 0.001\n",
    "        batch_size = 64\n",
    "        num_epochs = 2\n",
    "        hidden_size = 512\n",
    "    \n",
    "    send_telegram_message(f\"Using hyperparameters: learning_rate={learning_rate}, batch_size={batch_size}, num_epochs={num_epochs}, hidden_size={hidden_size}\")\n",
    "    return learning_rate, batch_size, num_epochs, hidden_size\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        return self.linear_relu_stack(x)\n",
    "\n",
    "def train_model(num_epochs, train_loader, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        epoch_loss /= len(train_loader)\n",
    "        epoch_losses.append(epoch_loss)\n",
    "        print(f'Epoch {epoch+1}, Loss: {epoch_loss:.4f}')\n",
    "        send_telegram_message(f'Epoch {epoch+1}, Loss: {epoch_loss:.4f}')\n",
    "    return epoch_losses\n",
    "\n",
    "# Clear previous messages before starting the main loop\n",
    "clear_previous_messages()\n",
    "\n",
    "while True:\n",
    "    learning_rate, batch_size, num_epochs, hidden_size = get_hyperparameters()\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    train_dataset = MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model = SimpleNet(hidden_size)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    send_telegram_message(\"Model training has started.\")\n",
    "    epoch_losses = train_model(num_epochs, train_loader, model, criterion, optimizer)\n",
    "    final_loss = epoch_losses[-1]\n",
    "    send_telegram_message(f\"Training complete. Final loss: {final_loss:.4f}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epoch_losses, marker='o', linestyle='-', color='b')\n",
    "    plt.title('Training Loss Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('training_loss_plot.png')\n",
    "    plt.close()\n",
    "\n",
    "    send_telegram_image('training_loss_plot.png')\n",
    "\n",
    "    command = request_user_input(\"Enter 'rerun' to train again with new parameters, or 'stop' to end the program:\")\n",
    "    if command == \"stop\":\n",
    "        send_telegram_message(\"Training stopped by user command.\")\n",
    "        break\n",
    "    elif command == \"rerun\":\n",
    "        send_telegram_message(\"Rerunning the training with new parameters.\")\n",
    "        continue\n",
    "    else:\n",
    "        send_telegram_message(\"Invalid command. Stopping the program.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\smart\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\smart\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleared previous messages. Last update ID: 265526405\n",
      "Sent message: Do you want to input hyperparameters? (yes/no), Response: {'ok': True, 'result': {'message_id': 248, 'from': {'id': 7166875544, 'is_bot': True, 'first_name': 'anorak', 'username': 'gladiator_anorak_bot'}, 'chat': {'id': 5255840420, 'first_name': 'Anorak', 'type': 'private'}, 'date': 1721912566, 'text': 'Do you want to input hyperparameters? (yes/no)'}}\n",
      "Sent message: Using hyperparameters: learning_rate=0.001, batch_size=64, num_epochs=2, hidden_size=512, Response: {'ok': True, 'result': {'message_id': 250, 'from': {'id': 7166875544, 'is_bot': True, 'first_name': 'anorak', 'username': 'gladiator_anorak_bot'}, 'chat': {'id': 5255840420, 'first_name': 'Anorak', 'type': 'private'}, 'date': 1721912622, 'text': 'Using hyperparameters: learning_rate=0.001, batch_size=64, num_epochs=2, hidden_size=512'}}\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 17307261.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 516636.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 7300526.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 4517554.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Sent message: Model training has started., Response: {'ok': True, 'result': {'message_id': 251, 'from': {'id': 7166875544, 'is_bot': True, 'first_name': 'anorak', 'username': 'gladiator_anorak_bot'}, 'chat': {'id': 5255840420, 'first_name': 'Anorak', 'type': 'private'}, 'date': 1721912626, 'text': 'Model training has started.'}}\n",
      "Epoch 1, Loss: 0.3107\n",
      "Sent message: Epoch 1, Loss: 0.3107, Response: {'ok': True, 'result': {'message_id': 252, 'from': {'id': 7166875544, 'is_bot': True, 'first_name': 'anorak', 'username': 'gladiator_anorak_bot'}, 'chat': {'id': 5255840420, 'first_name': 'Anorak', 'type': 'private'}, 'date': 1721912677, 'text': 'Epoch 1, Loss: 0.3107'}}\n",
      "Epoch 2, Loss: 0.1417\n",
      "Sent message: Epoch 2, Loss: 0.1417, Response: {'ok': True, 'result': {'message_id': 253, 'from': {'id': 7166875544, 'is_bot': True, 'first_name': 'anorak', 'username': 'gladiator_anorak_bot'}, 'chat': {'id': 5255840420, 'first_name': 'Anorak', 'type': 'private'}, 'date': 1721912738, 'text': 'Epoch 2, Loss: 0.1417'}}\n",
      "Sent message: Training complete. Final loss: 0.1417, Response: {'ok': True, 'result': {'message_id': 254, 'from': {'id': 7166875544, 'is_bot': True, 'first_name': 'anorak', 'username': 'gladiator_anorak_bot'}, 'chat': {'id': 5255840420, 'first_name': 'Anorak', 'type': 'private'}, 'date': 1721912739, 'text': 'Training complete. Final loss: 0.1417'}}\n",
      "Sent image: training_loss_plot.png, Response: {'ok': True, 'result': {'message_id': 255, 'from': {'id': 7166875544, 'is_bot': True, 'first_name': 'anorak', 'username': 'gladiator_anorak_bot'}, 'chat': {'id': 5255840420, 'first_name': 'Anorak', 'type': 'private'}, 'date': 1721912740, 'photo': [{'file_id': 'AgACAgUAAxkDAAP_ZqJNpH_avsME4AABhBDeLfO6e5tPAAIiwTEbaRsRVXvRH3UHiwxQAQADAgADcwADNQQ', 'file_unique_id': 'AQADIsExG2kbEVV4', 'file_size': 736, 'width': 90, 'height': 45}, {'file_id': 'AgACAgUAAxkDAAP_ZqJNpH_avsME4AABhBDeLfO6e5tPAAIiwTEbaRsRVXvRH3UHiwxQAQADAgADbQADNQQ', 'file_unique_id': 'AQADIsExG2kbEVVy', 'file_size': 7569, 'width': 320, 'height': 160}, {'file_id': 'AgACAgUAAxkDAAP_ZqJNpH_avsME4AABhBDeLfO6e5tPAAIiwTEbaRsRVXvRH3UHiwxQAQADAgADeAADNQQ', 'file_unique_id': 'AQADIsExG2kbEVV9', 'file_size': 28663, 'width': 800, 'height': 400}, {'file_id': 'AgACAgUAAxkDAAP_ZqJNpH_avsME4AABhBDeLfO6e5tPAAIiwTEbaRsRVXvRH3UHiwxQAQADAgADeQADNQQ', 'file_unique_id': 'AQADIsExG2kbEVV-', 'file_size': 35059, 'width': 1000, 'height': 500}]}}\n",
      "Sent message: Do you want to use GitHub? (yes/no), Response: {'ok': True, 'result': {'message_id': 256, 'from': {'id': 7166875544, 'is_bot': True, 'first_name': 'anorak', 'username': 'gladiator_anorak_bot'}, 'chat': {'id': 5255840420, 'first_name': 'Anorak', 'type': 'private'}, 'date': 1721912741, 'text': 'Do you want to use GitHub? (yes/no)'}}\n",
      "Sent message: Files acceptable for GitHub push: .\\Donagram.ipynb, .\\Donagram2.ipynb, .\\README.md, .\\telegrambot.ipynb, .\\training_loss_plot.png, .\\.git\\config, .\\.git\\description, .\\.git\\HEAD, .\\.git\\index, .\\.git\\packed-refs, .\\.git\\hooks\\applypatch-msg.sample, .\\.git\\hooks\\commit-msg.sample, .\\.git\\hooks\\fsmonitor-watchman.sample, .\\.git\\hooks\\post-update.sample, .\\.git\\hooks\\pre-applypatch.sample, .\\.git\\hooks\\pre-commit.sample, .\\.git\\hooks\\pre-merge-commit.sample, .\\.git\\hooks\\pre-push.sample, .\\.git\\hooks\\pre-rebase.sample, .\\.git\\hooks\\pre-receive.sample, .\\.git\\hooks\\prepare-commit-msg.sample, .\\.git\\hooks\\push-to-checkout.sample, .\\.git\\hooks\\sendemail-validate.sample, .\\.git\\hooks\\update.sample, .\\.git\\info\\exclude, .\\.git\\logs\\HEAD, .\\.git\\logs\\refs\\heads\\main, .\\.git\\logs\\refs\\remotes\\origin\\HEAD, .\\.git\\objects\\pack\\pack-31f3cc6b51bd432efd092610a963cb3224257729.idx, .\\.git\\objects\\pack\\pack-31f3cc6b51bd432efd092610a963cb3224257729.pack, .\\.git\\objects\\pack\\pack-31f3cc6b51bd432efd092610a963cb3224257729.rev, .\\.git\\refs\\heads\\main, .\\.git\\refs\\remotes\\origin\\HEAD, .\\data\\MNIST\\raw\\t10k-images-idx3-ubyte, .\\data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz, .\\data\\MNIST\\raw\\t10k-labels-idx1-ubyte, .\\data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz, .\\data\\MNIST\\raw\\train-images-idx3-ubyte, .\\data\\MNIST\\raw\\train-images-idx3-ubyte.gz, .\\data\\MNIST\\raw\\train-labels-idx1-ubyte, .\\data\\MNIST\\raw\\train-labels-idx1-ubyte.gz, Response: {'ok': True, 'result': {'message_id': 258, 'from': {'id': 7166875544, 'is_bot': True, 'first_name': 'anorak', 'username': 'gladiator_anorak_bot'}, 'chat': {'id': 5255840420, 'first_name': 'Anorak', 'type': 'private'}, 'date': 1721912745, 'text': 'Files acceptable for GitHub push: .\\\\Donagram.ipynb, .\\\\Donagram2.ipynb, .\\\\README.md, .\\\\telegrambot.ipynb, .\\\\training_loss_plot.png, .\\\\.git\\\\config, .\\\\.git\\\\description, .\\\\.git\\\\HEAD, .\\\\.git\\\\index, .\\\\.git\\\\packed-refs, .\\\\.git\\\\hooks\\\\applypatch-msg.sample, .\\\\.git\\\\hooks\\\\commit-msg.sample, .\\\\.git\\\\hooks\\\\fsmonitor-watchman.sample, .\\\\.git\\\\hooks\\\\post-update.sample, .\\\\.git\\\\hooks\\\\pre-applypatch.sample, .\\\\.git\\\\hooks\\\\pre-commit.sample, .\\\\.git\\\\hooks\\\\pre-merge-commit.sample, .\\\\.git\\\\hooks\\\\pre-push.sample, .\\\\.git\\\\hooks\\\\pre-rebase.sample, .\\\\.git\\\\hooks\\\\pre-receive.sample, .\\\\.git\\\\hooks\\\\prepare-commit-msg.sample, .\\\\.git\\\\hooks\\\\push-to-checkout.sample, .\\\\.git\\\\hooks\\\\sendemail-validate.sample, .\\\\.git\\\\hooks\\\\update.sample, .\\\\.git\\\\info\\\\exclude, .\\\\.git\\\\logs\\\\HEAD, .\\\\.git\\\\logs\\\\refs\\\\heads\\\\main, .\\\\.git\\\\logs\\\\refs\\\\remotes\\\\origin\\\\HEAD, .\\\\.git\\\\objects\\\\pack\\\\pack-31f3cc6b51bd432efd092610a963cb3224257729.idx, .\\\\.git\\\\objects\\\\pack\\\\pack-31f3cc6b51bd432efd092610a963cb3224257729.pack, .\\\\.git\\\\objects\\\\pack\\\\pack-31f3cc6b51bd432efd092610a963cb3224257729.rev, .\\\\.git\\\\refs\\\\heads\\\\main, .\\\\.git\\\\refs\\\\remotes\\\\origin\\\\HEAD, .\\\\data\\\\MNIST\\\\raw\\\\t10k-images-idx3-ubyte, .\\\\data\\\\MNIST\\\\raw\\\\t10k-images-idx3-ubyte.gz, .\\\\data\\\\MNIST\\\\raw\\\\t10k-labels-idx1-ubyte, .\\\\data\\\\MNIST\\\\raw\\\\t10k-labels-idx1-ubyte.gz, .\\\\data\\\\MNIST\\\\raw\\\\train-images-idx3-ubyte, .\\\\data\\\\MNIST\\\\raw\\\\train-images-idx3-ubyte.gz, .\\\\data\\\\MNIST\\\\raw\\\\train-labels-idx1-ubyte, .\\\\data\\\\MNIST\\\\raw\\\\train-labels-idx1-ubyte.gz', 'entities': [{'offset': 73, 'length': 9, 'type': 'url'}]}}\n",
      "Sent message: Do you want to push these files to GitHub? (yes/no), Response: {'ok': True, 'result': {'message_id': 259, 'from': {'id': 7166875544, 'is_bot': True, 'first_name': 'anorak', 'username': 'gladiator_anorak_bot'}, 'chat': {'id': 5255840420, 'first_name': 'Anorak', 'type': 'private'}, 'date': 1721912746, 'text': 'Do you want to push these files to GitHub? (yes/no)'}}\n",
      "Sent message: Enter your GitHub repository URL:, Response: {'ok': True, 'result': {'message_id': 261, 'from': {'id': 7166875544, 'is_bot': True, 'first_name': 'anorak', 'username': 'gladiator_anorak_bot'}, 'chat': {'id': 5255840420, 'first_name': 'Anorak', 'type': 'private'}, 'date': 1721912768, 'text': 'Enter your GitHub repository URL:'}}\n",
      "Sent message: Is this a private repository? (yes/no), Response: {'ok': True, 'result': {'message_id': 263, 'from': {'id': 7166875544, 'is_bot': True, 'first_name': 'anorak', 'username': 'gladiator_anorak_bot'}, 'chat': {'id': 5255840420, 'first_name': 'Anorak', 'type': 'private'}, 'date': 1721912777, 'text': 'Is this a private repository? (yes/no)'}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import git\n",
    "from git import Repo\n",
    "\n",
    "last_update_id = None\n",
    "\n",
    "def send_telegram_message(message):\n",
    "    TOKEN = '7166875544:AAGBi7azOdXowUbrZKXHpm7p152pG-mDxkA'  #creds\n",
    "    chat_id = '5255840420'  #creds\n",
    "    url = f\"https://api.telegram.org/bot{TOKEN}/sendMessage?chat_id={chat_id}&text={message}\"\n",
    "    response = requests.get(url)\n",
    "    print(f\"Sent message: {message}, Response: {response.json()}\")\n",
    "\n",
    "def send_telegram_image(image_path):\n",
    "    TOKEN = '7166875544:AAGBi7azOdXowUbrZKXHpm7p152pG-mDxkA'  #creds\n",
    "    chat_id = '5255840420'  #creds\n",
    "    url = f\"https://api.telegram.org/bot{TOKEN}/sendPhoto\"\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        files = {'photo': image_file}\n",
    "        data = {'chat_id': chat_id}\n",
    "        response = requests.post(url, files=files, data=data)\n",
    "    print(f\"Sent image: {image_path}, Response: {response.json()}\")\n",
    "\n",
    "def get_updates(offset=None):\n",
    "    TOKEN = '7166875544:AAGBi7azOdXowUbrZKXHpm7p152pG-mDxkA'  #creds\n",
    "    url = f\"https://api.telegram.org/bot{TOKEN}/getUpdates\"\n",
    "    params = {'offset': offset, 'timeout': 30}\n",
    "    response = requests.get(url, params=params).json()\n",
    "    return response.get('result', [])\n",
    "\n",
    "def clear_previous_messages():\n",
    "    global last_update_id\n",
    "    updates = get_updates()\n",
    "    if updates:\n",
    "        last_update_id = updates[-1]['update_id'] + 1\n",
    "    print(f\"Cleared previous messages. Last update ID: {last_update_id}\")\n",
    "\n",
    "def request_user_input(prompt):\n",
    "    global last_update_id\n",
    "    send_telegram_message(prompt)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    timeout = 300  # 5 minutes timeout\n",
    "\n",
    "    while time.time() - start_time < timeout:\n",
    "        updates = get_updates(last_update_id)\n",
    "        for update in updates:\n",
    "            last_update_id = update['update_id'] + 1\n",
    "            if 'message' in update and 'text' in update['message']:\n",
    "                return update['message']['text'].lower()\n",
    "        time.sleep(1)\n",
    "    \n",
    "    send_telegram_message(\"No input received within 5 minutes. Using default value.\")\n",
    "    return None\n",
    "\n",
    "def get_hyperparameters():\n",
    "    choice = request_user_input(\"Do you want to input hyperparameters? (yes/no)\")\n",
    "    \n",
    "    if choice == 'yes':\n",
    "        learning_rate = float(request_user_input(\"Enter learning rate (e.g., 0.001):\") or 0.001)\n",
    "        batch_size = int(request_user_input(\"Enter batch size (e.g., 64):\") or 64)\n",
    "        num_epochs = int(request_user_input(\"Enter number of epochs (e.g., 2):\") or 2)\n",
    "        hidden_size = int(request_user_input(\"Enter hidden layer size (e.g., 512):\") or 512)\n",
    "    else:\n",
    "        learning_rate = 0.001\n",
    "        batch_size = 64\n",
    "        num_epochs = 2\n",
    "        hidden_size = 512\n",
    "    \n",
    "    send_telegram_message(f\"Using hyperparameters: learning_rate={learning_rate}, batch_size={batch_size}, num_epochs={num_epochs}, hidden_size={hidden_size}\")\n",
    "    return learning_rate, batch_size, num_epochs, hidden_size\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        return self.linear_relu_stack(x)\n",
    "\n",
    "def train_model(num_epochs, train_loader, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        epoch_loss /= len(train_loader)\n",
    "        epoch_losses.append(epoch_loss)\n",
    "        print(f'Epoch {epoch+1}, Loss: {epoch_loss:.4f}')\n",
    "        send_telegram_message(f'Epoch {epoch+1}, Loss: {epoch_loss:.4f}')\n",
    "    return epoch_losses\n",
    "\n",
    "def check_file_sizes():\n",
    "    max_file_size = 100 * 1024 * 1024  # 100 MB (GitHub's file size limit)\n",
    "    acceptable_files = []\n",
    "    for root, dirs, files in os.walk('.'):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            if os.path.getsize(file_path) <= max_file_size:\n",
    "                acceptable_files.append(file_path)\n",
    "    return acceptable_files\n",
    "\n",
    "def push_to_github(repo_url, is_private):\n",
    "    try:\n",
    "        # Initialize or open the repository\n",
    "        if os.path.exists('.git'):\n",
    "            repo = Repo('.')\n",
    "        else:\n",
    "            repo = Repo.init('.')\n",
    "            repo.create_remote('origin', url=repo_url)\n",
    "\n",
    "        # Stage all files\n",
    "        repo.git.add(A=True)\n",
    "\n",
    "        # Commit\n",
    "        repo.index.commit(\"Update from Telegram bot\")\n",
    "\n",
    "        # Push\n",
    "        origin = repo.remote('origin')\n",
    "        origin.push()\n",
    "\n",
    "        send_telegram_message(\"Successfully pushed to GitHub repository.\")\n",
    "    except Exception as e:\n",
    "        send_telegram_message(f\"Error pushing to GitHub: {str(e)}\")\n",
    "\n",
    "# Clear previous messages before starting the main loop\n",
    "clear_previous_messages()\n",
    "\n",
    "while True:\n",
    "    learning_rate, batch_size, num_epochs, hidden_size = get_hyperparameters()\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    train_dataset = MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model = SimpleNet(hidden_size)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    send_telegram_message(\"Model training has started.\")\n",
    "    epoch_losses = train_model(num_epochs, train_loader, model, criterion, optimizer)\n",
    "    final_loss = epoch_losses[-1]\n",
    "    send_telegram_message(f\"Training complete. Final loss: {final_loss:.4f}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epoch_losses, marker='o', linestyle='-', color='b')\n",
    "    plt.title('Training Loss Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('training_loss_plot.png')\n",
    "    plt.close()\n",
    "\n",
    "    send_telegram_image('training_loss_plot.png')\n",
    "\n",
    "    # GitHub integration\n",
    "    use_github = request_user_input(\"Do you want to use GitHub? (yes/no)\")\n",
    "    if use_github == 'yes':\n",
    "        acceptable_files = check_file_sizes()\n",
    "        send_telegram_message(f\"Files acceptable for GitHub push: {', '.join(acceptable_files)}\")\n",
    "        \n",
    "        push_decision = request_user_input(\"Do you want to push these files to GitHub? (yes/no)\")\n",
    "        if push_decision == 'yes':\n",
    "            repo_url = request_user_input(\"Enter your GitHub repository URL:\")\n",
    "            is_private = request_user_input(\"Is this a private repository? (yes/no)\") == 'yes'\n",
    "            push_to_github(repo_url, is_private)\n",
    "\n",
    "    command = request_user_input(\"Enter 'rerun' to train again with new parameters, or 'stop' to end the program:\")\n",
    "    if command == \"stop\":\n",
    "        send_telegram_message(\"Training stopped by user command.\")\n",
    "        break\n",
    "    elif command == \"rerun\":\n",
    "        send_telegram_message(\"Rerunning the training with new parameters.\")\n",
    "        continue\n",
    "    else:\n",
    "        send_telegram_message(\"Invalid command. Stopping the program.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
